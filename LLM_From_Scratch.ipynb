{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6997f72d-bdb0-4136-aeeb-c25231a01097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import pdfplumber\n",
    "import re\n",
    "import tiktoken  #tiktoken.__version__=0.11.0\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "import urllib.request\n",
    "\n",
    "#Followed steps: Dataset preparation -> Tokenized -> Token IDs -> Token Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "120af25a-c3f8-42d5-b89f-eeb5fd386478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             CONTENT  CLASS\n",
      "0  <a href=\"http://www.youtube.com/watch?v=KQ6zr6...      0\n",
      "1                                   wierd but funny﻿      0\n",
      "2  Hey guys, I&#39;m a human.<br /><br /><br />Bu...      1\n",
      "3       Party Rock....lol...who wants to shuffle!!!﻿      0\n",
      "4                                        Party rock﻿      0\n",
      "CLASS\n",
      "1    1005\n",
      "0     951\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Dataset preparation\n",
    "dataset_path = \"youtube+spam+collection\"\n",
    "csv_files = [f for f in os.listdir(dataset_path) if f.endswith(\".csv\")]\n",
    "# Read and combine only Content and Class\n",
    "df = pd.concat(\n",
    "    [pd.read_csv(os.path.join(dataset_path, f), sep=\",\")[[\"CONTENT\", \"CLASS\"]] \n",
    "     for f in csv_files],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Show first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Count how many 0s and 1s in Class\n",
    "print(df[\"CLASS\"].value_counts())\n",
    "\n",
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "    \n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "    \n",
    "    # Split the DataFrame\n",
    "    train_df = df [:train_end]\n",
    "    validation_df = df[train_end: validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "                   \n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(df, 0.7, 0.1)\n",
    "\n",
    "# Test size is implied to be 0.2 as the remainder\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\",index=None)\n",
    "test_df.to_csv(\"test.Csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "13adc70e-35a0-41f7-a2db-4c5e383d7e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, text, tokenizer, max_length, stride):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        tokens = tokenizer.encode(text, allowed_special=tokenizer.special_tokens_set)\n",
    "        #tokens = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "        print (\"Tokens Size: \", len(tokens))\n",
    "        for i in range(0, len(tokens) - max_length, stride):\n",
    "            in_chunk = tokens[i : i + max_length]\n",
    "            t_chunk  = tokens[i + 1 : i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(in_chunk, dtype=torch.long))\n",
    "            self.target_ids.append(torch.tensor(t_chunk, dtype=torch.long))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0c7e2dc6-c88b-497f-b165-27098a9bec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(text, batch_size=4, max_length=256,stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    # Initialize the tokenizer\n",
    "    #print(tiktoken.list_encoding_names())\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    print(\"Tokenizer true token Size: \",tokenizer.n_vocab)\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(text, tokenizer, max_length, stride)\n",
    "    \n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader (dataset, batch_size = batch_size, shuffle=shuffle, drop_last = drop_last, num_workers = num_workers)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1c74dbe4-8be3-4869-868f-d6b6b4179e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embeddings\n",
    "vocab_size = 100277 #cl100k_base number of tokens\n",
    "output_dim = 256\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "position_embedding_layer = torch.nn.Embedding(max_length, output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "33ffe9a2-f079-4cfa-9371-994acfc34e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 8, 256])\n",
      "torch.Size([10, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "class CausalAttention (nn.Module):\n",
    "    \n",
    "    def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
    "        super ().__init__()\n",
    "        self.W_query = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        #self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "        self.register_buffer(\"mask\",torch.triu(torch.ones(context_length, context_length), diagonal=1).bool())\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        queries = self.W_query (x)\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        attn_scores = queries @ keys.transpose(1, 2) # .transpose(1, 2) swaps only the sequence and feature dims, giving [B, S, S] as intended.\n",
    "        attn_scores = attn_scores / (keys.shape[-1] ** 0.5)         # NEW (scale before softmax)\n",
    "        m = self.mask[:num_tokens, :num_tokens].to(x.device)\n",
    "        attn_scores.masked_fill_(m, -torch.inf) \n",
    "        attn_weights = torch.softmax (attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights) # New\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec, attn_weights\n",
    "        \n",
    "torch.manual_seed (789)\n",
    "d_in = d_out = final_embeddings.size(-1)\n",
    "context_length =  max_length\n",
    "dropout = 0.0\n",
    "ca = CausalAttention(d_in, d_out, context_length, dropout)\n",
    "context_vec, attn_weights = ca(final_embeddings)\n",
    "\n",
    "print(context_vec.shape)   # [B, S, D]\n",
    "print(attn_weights.shape)  # [B, S, S]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a852a1f6-729c-4525-9cca-36001c9731c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by n_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)  # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "986c4287-904f-4d1e-a673-341f253d4aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Creation\n",
    "\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 100277,\n",
    "    # Vocabulary size\n",
    "    \"context_length\": 512, # Context length\n",
    "    \"emb_dim\": 768,# Embedding dimension\n",
    "    \"n_heads\": 12,# Number of attention heads\n",
    "    \"n_layers\": 12,# Number of layers\n",
    "    \"drop_rate\": 0.1,# Dropout rate\n",
    "    \"qkv_bias\": False # Query-Key-Value bias\n",
    "}\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) *(x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "def print_gradients (model, X):\n",
    "    # Forward pass\n",
    "    output = model (x)\n",
    "    target = torch.tensor([[0.]])\n",
    "           \n",
    "    # Calculate loss based on how close the target\n",
    "    # and output are\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "        \n",
    "    # Backward pass to calculate the gradients\n",
    "    loss. backward ()\n",
    "    for name, param in model.named_parameters ():\n",
    "        if 'weight' in name:\n",
    "            # Print the mean absolute gradient of the weights\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(d_in=cfg[\"emb_dim\"],d_out=cfg[\"emb_dim\"],context_length=cfg[\"context_length\"],\n",
    "                                      num_heads=cfg[\"n_heads\"],dropout=cfg[\"drop_rate\"],qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_resid = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)   # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_resid(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed-forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_resid(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size,temperature=0.0,top_k=None, eos_id=None):\n",
    "    for _ in range (max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "            \n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:\n",
    "            top_logits, top_pos = torch.topk(logits, top_k)\n",
    "            new_logits = torch.where (condition=logits < top_logits[:, -1],\n",
    "                                     input=torch.tensor(float(\"-inf\")),\n",
    "                                     other=logits)\n",
    "\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "        else:\n",
    "            idx_next= torch.argmax(logits, dim=1, keepdim=True) #(batch , 1)\n",
    "\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "    \n",
    "        \n",
    "        idx = torch.cat((idx, idx_next), dim=1) # (batch, n_tokens+1)\n",
    "    \n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c8e6716c-dae7-40c4-b2e0-3d7101267d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special=tokenizer.special_tokens_set)\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze (0) # remove batch dimension as it is a tensor\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "82b95fe3-346d-44d9-86d9-c3ce5a304b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "cpu\n",
      "Tokenizer true token Size:  50257\n",
      "Tokens Size:  4741\n",
      "Tokenizer true token Size:  50257\n",
      "Tokens Size:  551\n"
     ]
    }
   ],
   "source": [
    "print(torch. cuda. is_available())\n",
    "print(torch.mps. is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len (text) )\n",
    "train_data = text[:split_idx]\n",
    "val_data = text[split_idx:]\n",
    "\n",
    "\n",
    "train_loader = create_dataloader_v1(train_data, batch_size=2, max_length=GPT_CONFIG_124M [\"context_length\"],\n",
    "                                    stride=GPT_CONFIG_124M[\"context_length\"] ,\n",
    "                                    drop_last=True, shuffle=True, num_workers=0)\n",
    "\n",
    "val_loader = create_dataloader_v1(val_data, batch_size=2, max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "                                  stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "                                  drop_last=False, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model (input_batch)\n",
    "    loss= torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None) :\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float (\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len (data_loader)\n",
    "    else:        \n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min (num_batches, len(data_loader) )\n",
    "        \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "7df72547-9043-4d35-837f-5e4b1e60289d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 11.704, Val loss 10.598\n",
      "Every effort moves you                                                  \n"
     ]
    }
   ],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, \n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    \n",
    "    # Main training loop\n",
    "    for epoch in range (num_epochs) :\n",
    "        model.train() # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients \n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "            \n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model (\n",
    "                model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen. append (tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "    \n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        Train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape [0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(model=model, idx=encoded, max_new_tokens=50, context_size=context_size)\n",
    "        \n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text. replace(\"\\n\", \" \")) # Compact print format model. train()\n",
    "    model.train()\n",
    "    \n",
    "model = GPTModel (GPT_CONFIG_124M)\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "num_epochs = 1\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(model, train_loader, val_loader, optimizer, device,\n",
    "                                                           num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "                                                           start_context=\"Every effort moves you\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3ae2d8f8-ff14-45cd-ab3e-4a574d319eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses) :\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    \n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\") \n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\" , label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend (loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True)) # only show integer labels on x-axis\n",
    "                                                                        \n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny() # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0) # Invisible plot for aligning ticks \n",
    "    ax2.set_xlabel(\"Tokens seen\" )\n",
    "    \n",
    "    fig.tight_layout() # Adjust layout to make room plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "        \n",
    "epochs_tensor = torch.linspace(0, num_epochs, len (train_losses))\n",
    "plot_losses (epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2c8934d1-1d31-4933-9580-5a6ab5255dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "1ece96f1-6ee8-4795-8feb-e26889a3af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "    \n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "    \n",
    "    # Split the DataFrame\n",
    "    train_df = df [:train_end]\n",
    "    validation_df = df[train_end: validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "                   \n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(df, 0.7, 0.1)\n",
    "\n",
    "# Test size is implied to be 0.2 as the remainder\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\",index=None)\n",
    "test_df.to_csv(\"test.Csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0c50cb5e-4aa3-4d44-9aac-998f71dcf560",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"CONTENT\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"CLASS\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n",
    "        # Note: A more pythonic version to implement this method\n",
    "        # is the following, which is also used in the next chapter:\n",
    "        # return max(len(encoded_text) for encoded_text in self.encoded_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9c6739ca-6392-4056-91de-d21929db5fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset (csv_file=\"train.csv\",max_length=None, tokenizer=tokenizer)\n",
    "print (train_dataset.max_length)\n",
    "val_dataset = SpamDataset(csv_file=\"validation.csv\",max_length=train_dataset.max_length, tokenizer=tokenizer)\n",
    "test_dataset = SpamDataset(csv_file=\"test.csv\",max_length=train_dataset.max_length, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5a5b9821-dc8e-484f-b73b-ef5b8417eaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e9b9178f-4034-4fe5-9d0e-3351397e688d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171 training batches\n",
      "25 validation batches\n",
      "49 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b9fe5411-401c-48e1-8c61-29de680d8853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "048337d1-cfbe-497b-add7-aae33853575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "12b924b5-eb68-442f-9fee-25d77a29392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d28e9e1e-68eb-445f-a9d3-3fd73db0090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "cff7fa39-3a3d-4cce-b583-2ad19244c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall the same as `train_model_simple` in chapter 5\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0d147979-d45c-428d-87b0-79ae6c465ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
    "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "    assert max_length is not None, (\n",
    "        \"max_length must be specified. If you want to use the full model context, \"\n",
    "        \"pass max_length=model.pos_emb.weight.shape[0].\"\n",
    "    )\n",
    "    assert max_length <= supported_context_length, (\n",
    "        f\"max_length ({max_length}) exceeds model's supported context length ({supported_context_length}).\"\n",
    "    )    \n",
    "    # Alternatively, a more robust version is the following one, which handles the max_length=None case better\n",
    "    # max_len = min(max_length,supported_context_length) if max_length else supported_context_length\n",
    "    # input_ids = input_ids[:max_len]\n",
    "    \n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "47502a7e-f325-4176-b7de-c823302315c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n",
      "not spam\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))\n",
    "\n",
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))\n",
    "\n",
    "torch.save(model.state_dict(), \"review_classifier.pth\")\n",
    "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device, weights_only=True)\n",
    "model.load_state_dict(model_state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03791b3-c897-46b2-80f7-e97dac36ba1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b230b9-cf01-42b1-828a-fb3220296f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d7d8d8-661d-470e-ba0c-b1ab0d1bcb47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
